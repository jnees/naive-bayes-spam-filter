{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Filtering Spam with Naive Bayes\n",
    "\n",
    "#### Overview\n",
    "\n",
    "The goal of this project is to test the effectiveness of the Multinomial Naive Bayes classification algorithm as an spam filter for SMS messages. This technique is not limited to SMS messages and could be applied to a broad range of text classification problems (emails, comments, product reviews, etc.) given that training data with labels is available. While this case aims to predict one of two labels (spam/non-spam), the model could be expanded to cases with a greater number of labels as well.\n",
    "\n",
    "The dataset that I am using for testing comes from Tiago A. Almeida and José María Gómez Hidalgo and is hosted on [the UCI Machine Learning Repository](https://archive.ics.uci.edu/ml/datasets/sms+spam+collection). It includes 5,572 SMS messages which have been classified by humans as either \"spam\" or \"ham\" (non-spam).\n",
    "\n",
    "#### Results\n",
    "\n",
    "The naive bayes model was a highly effective predictor for this dataset, achieving 98.8% label accuracy on the test partition of the dataset.\n",
    "\n",
    "||Actual Spam|Actual Ham|Total|\n",
    "|--|--|--|--|\n",
    "|Predicted Spam|139|5|<b>  144|\n",
    "|Predicted Ham|8|963|<b>  971|\n",
    "|<b>Total|<b>147|<b>968|<b> 1155|\n",
    "\n",
    "\n",
    "#### Discussion\n",
    "\n",
    "One of the major benefits of this model was how easy it was to set it up. It required only a small amount of text cleaning and manupulation with Pandas to get the data in a usable format. The classifier itself is just a custom is just a basic conditional probability calculation and requires no additional libraries.\n",
    "\n",
    "On the other hand, the simplicity of the model makes it somewhat difficult to tweak and customize for different circumstances. For example, if there is a situation in which false positives are unacceptable, there isn't an obvious  parameter to adjust to achieve this. A workaround could be to adjust the comparison function so that the P(spam | message) must be some % higher than P(non-spam | message), but this would require some trial and error to find a suitable amount.\n",
    "\n",
    "A potential issue with this model is that as the word count of a given message increases by n, the number of probabilities being multiplied together in the comparison formulas also increases by n. This causes the resulting number to grow smaller and given a high enough word count could lead to underflow and innaccurate predictions. One potential work around for this is to convert the calculations to a log scale."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "pd.set_option('display.max_colwidth', 65)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"SMSSpamCollection\", sep=\"\\t\", header=None, names=['Label', 'SMS'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Label                                                               SMS\n",
      "0   ham  Go until jurong point, crazy.. Available only in bugis n grea...\n",
      "1   ham                                     Ok lar... Joking wif u oni...\n",
      "2  spam  Free entry in 2 a wkly comp to win FA Cup final tkts 21st May...\n",
      "3   ham                 U dun say so early hor... U c already then say...\n",
      "4   ham     Nah I don't think he goes to usf, he lives around here though\n",
      "5  spam  FreeMsg Hey there darling it's been 3 week's now and no word ...\n",
      "6   ham  Even my brother is not like to speak with me. They treat me l...\n",
      "7   ham  As per your request 'Melle Melle (Oru Minnaminunginte Nurungu...\n",
      "8  spam  WINNER!! As a valued network customer you have been selected ...\n",
      "9  spam  Had your mobile 11 months or more? U R entitled to Update to ...\n"
     ]
    }
   ],
   "source": [
    "print(df.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Summary Stats\n",
    "\n",
    " - 5,572 total messages.\n",
    " - 13.4% of the messages are classified as spam.\n",
    " - Avg. length of SMS: 80 characters\n",
    " - Longest SMS: 910 characters\n",
    " - Shortest SMS: 2 characters\n",
    " - 403 messages are duplicates (see duplicates section)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5572, 2)\n",
      "ham     0.865937\n",
      "spam    0.134063\n",
      "Name: Label, dtype: float64\n",
      "80.48994974874371\n",
      "910\n",
      "2\n",
      "403\n"
     ]
    }
   ],
   "source": [
    "print(df.shape)\n",
    "print(df[\"Label\"].value_counts(normalize=True))\n",
    "print(df.SMS.map(lambda x: len(x)).mean())\n",
    "print(df.SMS.map(lambda x: len(x)).max())\n",
    "print(df.SMS.map(lambda x: len(x)).min())\n",
    "print(df.duplicated().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Duplicate Values\n",
    "\n",
    "This dataset contains 403 duplicate SMS messages. In this case, it doesn't necessarily mean that they are the same message recorded twice, but rather they could be the same message being sent at different times or between different people. It makes sense to see duplicates in spam because they are automated and sent to multiple people. In the case of \"ham\" messages, these might be generic replies such as \"Sorry, I'll call later.\" or information sent to multiple people.\n",
    "\n",
    "I've decided to retain the records since they came from a natural sampling processes and not an overlap in the data. This may introduce some slight bias by overrepresenting the words in these messages. In this case, the duplicate messages are 23% spam whereas spam messages make up only 13% of the dataset. \n",
    "\n",
    "Another way to look at this is that since the real world contains duplicate messages, it is probably appropriate that the training set keep the duplicate messages as well. [Interesting discussion on the topic.](https://stackoverflow.com/questions/26197700/should-i-keep-remove-identical-training-examples-that-represent-different-object)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ham     0.766749\n",
      "spam    0.233251\n",
      "Name: Label, dtype: float64\n",
      "    Label                                                               SMS\n",
      "103   ham  As per your request 'Melle Melle (Oru Minnaminunginte Nurungu...\n",
      "154   ham  As per your request 'Melle Melle (Oru Minnaminunginte Nurungu...\n",
      "207   ham  As I entered my cabin my PA said, '' Happy B'day Boss !!''. I...\n",
      "223   ham                                            Sorry, I'll call later\n",
      "326   ham                                  No calls..messages..missed calls\n",
      "339   ham                                            Sorry, I'll call later\n",
      "444   ham                                            Sorry, I'll call later\n",
      "533   ham                                 Gudnite....tc...practice going on\n",
      "655   ham                                      Did u got that persons story\n",
      "658   ham                              You will be in the place of that man\n",
      "\n",
      "\n",
      "     Label                                                               SMS\n",
      "357   spam  Congratulations ur awarded 500 of CD vouchers or 125gift guar...\n",
      "850   spam  Today's Offer! Claim ur £150 worth of discount vouchers! Text...\n",
      "900   spam  Your free ringtone is waiting to be collected. Simply text th...\n",
      "1002  spam  Please call our customer service representative on FREEPHONE ...\n",
      "1163  spam  Free entry in 2 a wkly comp to win FA Cup final tkts 21st May...\n",
      "1225  spam  You are a winner U have been specially selected 2 receive £10...\n",
      "1380  spam  No. 1 Nokia Tone 4 ur mob every week! Just txt NOK to 87021. ...\n",
      "1691  spam  Sunshine Quiz Wkly Q! Win a top Sony DVD player if u know whi...\n",
      "1780  spam  Loan for any purpose £500 - £75,000. Homeowners + Tenants wel...\n",
      "1876  spam  HMV BONUS SPECIAL 500 pounds of genuine HMV vouchers to be wo...\n"
     ]
    }
   ],
   "source": [
    "duplicates = df[df.duplicated() == True]\n",
    "print(duplicates[\"Label\"].value_counts(normalize=True))\n",
    "print(duplicates[duplicates[\"Label\"] == 'ham'].head(10))\n",
    "print(\"\\n\")\n",
    "print(duplicates[duplicates[\"Label\"] == 'spam'].head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training / Test Split\n",
    "\n",
    "The data will randomized and 20% of messages withheld for testing without cross-validation. The resulting samples have a similar label distribution to the full dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Randomize\n",
    "df = df.sample(frac=1, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split\n",
    "train = df.iloc[:4457].copy().reset_index(drop=True)\n",
    "test = df.iloc[4457:].copy().reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ham     0.86538\n",
      "spam    0.13462\n",
      "Name: Label, dtype: float64\n",
      "ham     0.868161\n",
      "spam    0.131839\n",
      "Name: Label, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(train[\"Label\"].value_counts(normalize=True))\n",
    "print(test[\"Label\"].value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleaning and Formating\n",
    "\n",
    "In this implementation, I will be standardizing the SMS texts to lowercase and removing punctuation. A more nuanced model, if needed, could perhaps give consideration to these factors.\n",
    "\n",
    "I will also be spliting each word in the vocabulary (all words used in training) to columns. The value of each column will be the number of times in the SMS text that the individual word was used. This will make it easy to find and plug in the word counts needed for scoring. Example:\n",
    "\n",
    "|Label|'Secret'|'Prize'|'Claim'|'Money'|'Now'|\n",
    "|---|---|---|---|---|---|\n",
    "|Spam|0|1|1|1|1|\n",
    "|Ham|0|0|0|0|1|\n",
    "|Ham|1|0|0|0|0|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Data clean\n",
    "train['SMS'] = train['SMS'].str.replace('\\W', ' ')\n",
    "train['SMS'] = train['SMS'].str.lower().str.split()\n",
    "\n",
    "vocabulary = []\n",
    "for row in train['SMS']:\n",
    "    for word in row:\n",
    "        vocabulary.append(word)\n",
    "        \n",
    "vocabulary = list(set(vocabulary))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                                   [yep, by, the, pretty, sculpture]\n",
       "1                [yes, princess, are, you, going, to, make, me, moan]\n",
       "2                                     [welp, apparently, he, retired]\n",
       "3                                                            [havent]\n",
       "4    [i, forgot, 2, ask, ü, all, smth, there, s, a, card, on, da, ...\n",
       "5    [ok, i, thk, i, got, it, then, u, wan, me, 2, come, now, or, ...\n",
       "6    [i, want, kfc, its, tuesday, only, buy, 2, meals, only, 2, no...\n",
       "7                                     [no, dear, i, was, sleeping, p]\n",
       "8                                          [ok, pa, nothing, problem]\n",
       "9                                    [ill, be, there, on, lt, gt, ok]\n",
       "Name: SMS, dtype: object"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[\"SMS\"].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_counts_per_sms = {unique_word: [0] * len(train['SMS']) for unique_word in vocabulary}\n",
    "\n",
    "for index, sms in enumerate(train['SMS']):\n",
    "    for word in sms:\n",
    "        word_counts_per_sms[word][index] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_counts = pd.DataFrame.from_dict(word_counts_per_sms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_df = pd.concat([train, train_counts], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate Constants\n",
    "\n",
    "Multinomial naive bayes uses the following calculations to score each incoming message based on words previously observed in the training data. The formula with the higher resulting score determines whether the message will be classified as either Spam or Ham.\n",
    "\n",
    "$$\n",
    "P(Spam | w_1,w_2, ..., w_n) \\propto P(Spam) \\cdot \\prod_{i=1}^{n}P(w_i|Spam)\n",
    "$$$$\n",
    "P(Ham | w_1,w_2, ..., w_n) \\propto P(Ham) \\cdot \\prod_{i=1}^{n}P(w_i|Ham)\n",
    "$$\n",
    "\n",
    " $$\n",
    "P(w_i|Spam) = \\frac{N_{w_i|Spam} + \\alpha}{N_{Spam} + \\alpha \\cdot N_{Vocabulary}}\n",
    "$$$$\n",
    "P(w_i|Ham) = \\frac{N_{w_i|Ham} + \\alpha}{N_{Ham} + \\alpha \\cdot N_{Vocabulary}}\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Split dataframes by label\n",
    "ham_df = training_df[training_df[\"Label\"] == \"ham\"].copy()\n",
    "spam_df = training_df[training_df[\"Label\"] == \"spam\"].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Probability that message is ham or spam\n",
    "p_ham = ham_df.shape[0] / training_df.shape[0]\n",
    "p_spam = spam_df.shape[0] / training_df.shape[0]\n",
    "\n",
    "## Number of total words\n",
    "n_vocab_total = len(vocabulary)\n",
    "\n",
    "## Number of words in spam messages\n",
    "n_vocab_given_spam = spam_df['SMS'].apply(len)\n",
    "n_vocab_given_spam = n_vocab_given_spam.sum()\n",
    "\n",
    "# Number of woords in ham messages\n",
    "n_vocab_given_ham = ham_df[\"SMS\"].apply(len)\n",
    "n_vocab_given_ham = n_vocab_given_ham.sum()\n",
    "\n",
    "## Laplace Smoothing\n",
    "alpha = 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.13461969934933812\n",
      "0.8653803006506618\n",
      "7782\n",
      "15190\n",
      "57233\n"
     ]
    }
   ],
   "source": [
    "print(p_spam)\n",
    "print(p_ham)\n",
    "print(n_vocab_total)\n",
    "print(n_vocab_given_spam)\n",
    "print(n_vocab_given_ham)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate Parameters\n",
    "\n",
    "In addition to constants, naive bayes relies on a few parameters that can be pre-calculated to save time in classification. \n",
    "\n",
    "This section creates two dictionaries, one for messages labeled ham and one for spam. Each contains each word from the training vocabulary and the probability that the word is found in a message given that it is spam or ham.\n",
    "\n",
    "The \"calculate parameters\" cell calculates these functions and loads them into the dictionaries:\n",
    "\n",
    " $$\n",
    "P(w_i|Spam) = \\frac{N_{w_i|Spam} + \\alpha}{N_{Spam} + \\alpha \\cdot N_{Vocabulary}}\n",
    "$$$$\n",
    "P(w_i|Ham) = \\frac{N_{w_i|Ham} + \\alpha}{N_{Ham} + \\alpha \\cdot N_{Vocabulary}}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Initialize parameter hash tables\n",
    "parameters_ham = {unique_word:0 for unique_word in vocabulary}\n",
    "parameters_spam = {unique_word:0 for unique_word in vocabulary}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Calculate parameters\n",
    "for word in vocabulary:\n",
    "    ## P(w_i|Ham)\n",
    "    n_word_given_ham = ham_df[word].sum()\n",
    "    p_word_given_ham = (n_word_given_ham + alpha) / (n_vocab_given_ham + alpha * n_vocab_total)\n",
    "    parameters_ham[word] = p_word_given_ham\n",
    "    \n",
    "    ## P(w_i|Spam)\n",
    "    n_word_given_spam = spam_df[word].sum()\n",
    "    p_word_given_spam = (n_word_given_spam + alpha) / (n_vocab_given_spam + alpha * n_vocab_total)\n",
    "    parameters_spam[word] = p_word_given_spam\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification function\n",
    "\n",
    "With constants and parameters calculated, messaages can now be classified. In the classify function, each of the comparison formulas starts out as the observed percentages of spam/ham messages in the training data. For each word, the (P_w | Ham) and (P_w | Spam) are calculated and multiplied to the initial percentage. If the word is not found in the training vocabulary, then it is ignored. The formula with the largest total at the end of the message determines the classification.\n",
    "\n",
    "In testing a few new messages, the classifier looks promising.\n",
    "\n",
    "|Label|Message|\n",
    "|---|---|\n",
    "|Spam|CONGRATULATIONS! You have been selected for a secret prize.|\n",
    "|Ham|Thanks for your message.|\n",
    "|Ham|We need more Bort license plates in the gift shop.|\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify(message):\n",
    "    \n",
    "    # Text clean up\n",
    "    message = re.sub(\"\\W\", \" \", message).lower().split()\n",
    "    \n",
    "    # Initial guess -> prior probabilities from training set.\n",
    "    p_ham_given_message = p_ham\n",
    "    p_spam_given_message = p_spam\n",
    "    \n",
    "    # Adjust probabilities for each word in new message:\n",
    "    for word in message:\n",
    "        if word in parameters_ham:\n",
    "            p_ham_given_message *= parameters_ham[word]\n",
    "            \n",
    "        if word in parameters_spam:\n",
    "            p_spam_given_message *= parameters_spam[word]\n",
    "            \n",
    "    if p_spam_given_message > p_ham_given_message:\n",
    "        return \"spam\"\n",
    "    else:\n",
    "        return \"ham\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spam\n",
      "ham\n",
      "ham\n"
     ]
    }
   ],
   "source": [
    "## Gut check\n",
    "test_spam = 'CONGRATULATIONS. You have been selected for a secret prize.'\n",
    "test_ham = \"Thanks for your message.\"\n",
    "test_simpsons_quote = 'We need more Bort license plates in the gift shop.'\n",
    "\n",
    "print(classify(test_spam))\n",
    "print(classify(test_ham))\n",
    "print(classify(test_simpsons_quote))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Predictions and Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict\n",
    "test[\"prediction\"] = test[\"SMS\"].apply(classify)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "98.83%\n"
     ]
    }
   ],
   "source": [
    "# Percentage accuracy\n",
    "correct_pct = round(((test[\"prediction\"] == test[\"Label\"]).sum() / test.shape[0]) * 100, 2)\n",
    "print(str(correct_pct) + \"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Decomposing accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 false positives\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>SMS</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>153</td>\n",
       "      <td>ham</td>\n",
       "      <td>Unlimited texts. Limited minutes.</td>\n",
       "      <td>spam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>ham</td>\n",
       "      <td>26th OF JULY</td>\n",
       "      <td>spam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>285</td>\n",
       "      <td>ham</td>\n",
       "      <td>Nokia phone is lovly..</td>\n",
       "      <td>spam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>303</td>\n",
       "      <td>ham</td>\n",
       "      <td>No calls..messages..missed calls</td>\n",
       "      <td>spam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>320</td>\n",
       "      <td>ham</td>\n",
       "      <td>We have sent JD for Customer Service cum Accounts Executive t...</td>\n",
       "      <td>spam</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Label                                                               SMS  \\\n",
       "153   ham                                 Unlimited texts. Limited minutes.   \n",
       "160   ham                                                      26th OF JULY   \n",
       "285   ham                                            Nokia phone is lovly..   \n",
       "303   ham                                  No calls..messages..missed calls   \n",
       "320   ham  We have sent JD for Customer Service cum Accounts Executive t...   \n",
       "\n",
       "    prediction  \n",
       "153       spam  \n",
       "160       spam  \n",
       "285       spam  \n",
       "303       spam  \n",
       "320       spam  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# False Positives - Predicted a ham message to be spam.\n",
    "false_positives = test[(test[\"prediction\"] == \"spam\") & (test[\"Label\"] == \"ham\")]\n",
    "print(str(false_positives.shape[0]) + \" false positives\")\n",
    "false_positives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8 false negatives\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>SMS</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>115</td>\n",
       "      <td>spam</td>\n",
       "      <td>Not heard from U4 a while. Call me now am here all night with...</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>136</td>\n",
       "      <td>spam</td>\n",
       "      <td>More people are dogging in your area now. Call 09090204448 an...</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>505</td>\n",
       "      <td>spam</td>\n",
       "      <td>Oh my god! I've found your number again! I'm so glad, text me...</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>547</td>\n",
       "      <td>spam</td>\n",
       "      <td>Hi babe its Chloe, how r u? I was smashed on saturday night, ...</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>742</td>\n",
       "      <td>spam</td>\n",
       "      <td>0A$NETWORKS allow companies to bill for SMS, so they are resp...</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>877</td>\n",
       "      <td>spam</td>\n",
       "      <td>RCT' THNQ Adrian for U text. Rgds Vatian</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>886</td>\n",
       "      <td>spam</td>\n",
       "      <td>2/2 146tf150p</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>954</td>\n",
       "      <td>spam</td>\n",
       "      <td>Hello. We need some posh birds and chaps to user trial prods ...</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Label                                                               SMS  \\\n",
       "115  spam  Not heard from U4 a while. Call me now am here all night with...   \n",
       "136  spam  More people are dogging in your area now. Call 09090204448 an...   \n",
       "505  spam  Oh my god! I've found your number again! I'm so glad, text me...   \n",
       "547  spam  Hi babe its Chloe, how r u? I was smashed on saturday night, ...   \n",
       "742  spam  0A$NETWORKS allow companies to bill for SMS, so they are resp...   \n",
       "877  spam                          RCT' THNQ Adrian for U text. Rgds Vatian   \n",
       "886  spam                                                     2/2 146tf150p   \n",
       "954  spam  Hello. We need some posh birds and chaps to user trial prods ...   \n",
       "\n",
       "    prediction  \n",
       "115        ham  \n",
       "136        ham  \n",
       "505        ham  \n",
       "547        ham  \n",
       "742        ham  \n",
       "877        ham  \n",
       "886        ham  \n",
       "954        ham  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# False Negatives - Predicted a spam message to be ham.\n",
    "false_negatives = test[(test[\"prediction\"] == \"ham\") & (test[\"Label\"] == \"spam\")]\n",
    "print(str(false_negatives.shape[0]) + \" false negatives\")\n",
    "false_negatives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "139 true positives\n"
     ]
    }
   ],
   "source": [
    "# True Positives - Predicted spam for spam message\n",
    "true_positives = test[(test[\"Label\"] == \"spam\") & (test[\"prediction\"] == \"spam\")]\n",
    "print(str(true_positives.shape[0]) + \" true positives\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "963 true negatives\n"
     ]
    }
   ],
   "source": [
    "# True Negatives - Predicted ham for ham message\n",
    "true_negatives = test[(test[\"Label\"] == \"ham\") & (test[\"prediction\"] == \"ham\")]\n",
    "print(str(true_negatives.shape[0]) + \" true negatives\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
